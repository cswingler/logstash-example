input {
  # This is the main Beats input:
  beats {
    port => 10200
  }

  # Accept Filebeat/TLS on port 5000 
  beats {
    port => 5000
    codec => json
    ssl => true
    ssl_certificate => "/usr/share/logstash/pki/lumberjack.cert"
    ssl_key => "/usr/share/logstash/pki/lumberjack.key"
  }
}

filter {}

output {
  # Kubernetes filebeat forwarder has its own completely different message fields,
  # which means we have to pick completely different attributes off of it in order to
  # make reasonable-looking logs
  # Luckily, we can also identify kubernetes messages by the "kubernetes" top-level attribute
  file { 
    path => "/data/raw.log"
    codec => "json_lines"
  }
  if [kubernetes] {
    file {
      path => "/data/kubernetes/%{[kubernetes][container][name]}/%{+yyyy.MM.dd}.%{[kubernetes][pod][name]}.gz"
      # Only log the message payload, not what server it's on
      codec => line { format => "%{log}"}
      gzip => true
      }
    file {
      path => "/data/by-service/%{[kubernetes][container][name]}/%{+yyyy.MM.dd}.gz"
      # Log the timestamp, server, and the message body
      codec => line { format => "%{@timestamp} %{[kubernetes][pod][name]} %{log}"}
      gzip => true
    }
  }
  else {
    file {
      path => "/data/by-host/%{host}/%{type}.%{+yyyy.MM.dd}.gz"
      # Only log the message payload, not what server it's on
      codec => line { format => "%{message}"}
      gzip => true
    }
    file {
      path => "/data/by-service/%{type}/%{+yyyy.MM.dd}.gz"
      # Log the timestamp, server, and the message body
      codec => line { format => "%{@timestamp} %{host} %{message}"}
      gzip => true
    }
  }
}
